{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №1. Метрические алгоритмы классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполнили: Рутин Василий, Гордеев Станислав"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все лабораторные работы доступны по адресу: https://github.com/Omenstudio/ML_IFMO_LABS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Постановка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. На языке Python программно реализовать два метрических алгоритма классификации: Naive Bayes и K Nearest Neighbours\n",
    "\n",
    "2. Сравнить работу реализованных алгоритмов с библиотечными из scikit-learn\n",
    "\n",
    "3. Для тренировки, теста и валидации использовать один из предложенных датасетов (либо найти самостоятельно и внести в таблицу)\n",
    "\n",
    "4. Сформировать краткий отчет (постановка задачи, реализация, эксперимент с данными, полученные характеристики, вывод\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Исходные данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача классификации: определение наличия заболевания (диабет) у женщин.<br>\n",
    "Датасет доступен по адресу: https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество записей: 768<br>\n",
    "Количество атрибутов: 8 плюс класс.<br>\n",
    "Все атрибуты представлены числовыми значениями:\n",
    "1. Количество беременностей (шт.)\n",
    "2. Концентрация плазмы глюкозы (ммоль/л)\n",
    "3. Диастолическое давление (мм. рт. столба)\n",
    "4. Толщина кожной складки (мм.)\n",
    "5. Содержание инсулина (мкЕд/мл)\n",
    "6. Индекс массы тела (кг/м2)\n",
    "7. Предрасположенность по родословной линии (Diabetes pedigree function)\n",
    "8. Возраст (лет)\n",
    "9. Класс: наличие диабета (0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация KNN и NaiveBayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Были реализованы два алгоритма классификации: Наивный Байесовский и Метод K ближайших соседей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Метод K ближайших соседей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class MyKNN:\n",
    "\n",
    "    def __init__(self, n_neighbors=5):\n",
    "        self.train_inputs = []\n",
    "        self.train_outputs = []\n",
    "        self.K = n_neighbors\n",
    "\n",
    "    def fit(self, inputs, outputs):\n",
    "        \"\"\"\n",
    "        \"Обучает\" классификатор.\n",
    "        По факту тупо запоминает значения, чтобы использовать в дальнейшем.\n",
    "        :param inputs:\n",
    "        :param outputs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        self.train_inputs = inputs\n",
    "        self.train_outputs = outputs\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\"\n",
    "        Классифицирует входные данные\n",
    "        :param inputs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        res = []\n",
    "        for x in range(len(inputs)):\n",
    "            neighbors = self.__get_neighbors(inputs[x])\n",
    "            result = self.select_neighbor(neighbors)\n",
    "            res.append(result)\n",
    "        return res\n",
    "\n",
    "    def __get_neighbors(self, test_object):\n",
    "        \"\"\"\n",
    "        Возвращает список блажайших К соседей\n",
    "        :param test_object:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        distances = []\n",
    "        length = len(test_object)\n",
    "        for i in range(len(self.train_inputs)):\n",
    "            dist = self.dist(test_object, self.train_inputs[i], length)\n",
    "            distances.append((self.train_outputs[i], dist))\n",
    "        distances.sort(key=operator.itemgetter(1))\n",
    "        neighbors = []\n",
    "        for i in range(self.K):\n",
    "            neighbors.append(distances[i][0])\n",
    "        return neighbors\n",
    "\n",
    "    def dist(self, object_a, object_b, d):\n",
    "        \"\"\"\n",
    "        Находит евклидово расстояние в D-мерном пространстве\n",
    "        :param object_a:\n",
    "        :param object_b:\n",
    "        :param d:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        distance = 0\n",
    "        for i in range(d):\n",
    "            distance += pow((object_a[i] - object_b[i]), 2)\n",
    "        return math.sqrt(distance)\n",
    "\n",
    "    def select_neighbor(self, neighbors):\n",
    "        \"\"\"\n",
    "        Выбирает класс соседей\n",
    "        :param neighbors:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        res_dict = defaultdict(int)\n",
    "        for x in neighbors:\n",
    "            res_dict[x] += 1\n",
    "        res = sorted(res_dict.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        return res[0][0]\n",
    "\n",
    "    def score(self, inputs, outputs):\n",
    "        \"\"\"\n",
    "        Классифицирует входные данные и возвращает посчитанную точность по известным выходным данным.\n",
    "        :param inputs:\n",
    "        :param outputs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        predicted = self.predict(inputs)\n",
    "        correct = 0\n",
    "        for i in range(len(outputs)):\n",
    "            if outputs[i] == predicted[i]:\n",
    "                correct += 1\n",
    "        return correct/float(len(outputs))\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'MyKNN with N_neighbors={}'.format(self.K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наивный байсовский алгоритм."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from collections import defaultdict\n",
    "\n",
    "\n",
    "class MyGaussianNaiveBayes:\n",
    "\n",
    "    def __init__(self):\n",
    "        self.__summaries = None\n",
    "\n",
    "    def fit(self, inputs, outputs):\n",
    "        \"\"\"\n",
    "        Обучает классификатор по входным inputs и выходным outputs данным.\n",
    "        :param inputs:\n",
    "        :param outputs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        class_dict = self.__combine_by_class(inputs, outputs)\n",
    "        self.__summaries = {}\n",
    "        for k, v in class_dict.items():\n",
    "            self.__summaries[k] = self.__calc_params(v)\n",
    "\n",
    "    def __combine_by_class(self, inputs, outputs):\n",
    "        \"\"\"\n",
    "        Разделяет обучающую выборку по классам таким образом,\n",
    "        чтобы можно было получить все элементы, принадлежащие определенному классу.\n",
    "        :param inputs:\n",
    "        :param outputs:\n",
    "        :return: dict[class, elems]\n",
    "        \"\"\"\n",
    "        res = defaultdict(list)\n",
    "        for i in range(len(inputs)):\n",
    "            res[outputs[i]].append(inputs[i])\n",
    "        return res\n",
    "\n",
    "    def __calc_params(self, dataset):\n",
    "        \"\"\"\n",
    "        :param dataset:\n",
    "        :return: Среднее значение и среднеквадратичное отклонение для каждого \"свойства\" входных данных\n",
    "        \"\"\"\n",
    "        return [(self.mean(attribute), self.stdev(attribute)) for attribute in zip(*dataset)]\n",
    "\n",
    "    def mean(self, mas):\n",
    "        \"\"\"\n",
    "        :param mas:\n",
    "        :return: среднее значение массива mas\n",
    "        \"\"\"\n",
    "        return sum(mas) / float(len(mas))\n",
    "\n",
    "    def stdev(self, mas):\n",
    "        \"\"\"\n",
    "        :param numbers:\n",
    "        :return: среднеквадратичное отклонение в массиве mas\n",
    "        \"\"\"\n",
    "        avg = self.mean(mas)\n",
    "        variance = sum([pow(x-avg, 2) for x in mas])/float(len(mas)-1)\n",
    "        return math.sqrt(variance)\n",
    "\n",
    "\n",
    "    def predict(self, inputs):\n",
    "        \"\"\"\n",
    "        Классифицирует входные данные\n",
    "        :param inputs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        for i in range(len(inputs)):\n",
    "            result = self.__predict_single(inputs[i])\n",
    "            predictions.append(result)\n",
    "        return predictions\n",
    "\n",
    "    def __predict_single(self, input_data):\n",
    "        \"\"\"\n",
    "        Классифицирует один объект.\n",
    "        :param input_data:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        probabilities = self.__calc_allclass_probabilities(input_data)\n",
    "        className, res = None, -1\n",
    "        for classValue, probability in probabilities.items():\n",
    "            if className is None or probability > res:\n",
    "                res = probability\n",
    "                className = classValue\n",
    "        return className\n",
    "\n",
    "    def __calc_allclass_probabilities(self, input_data):\n",
    "        \"\"\"\n",
    "        Считает вероятности принадлежности объекта ко всем классам\n",
    "        :param input_data:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        res = {}\n",
    "        for className, classValues in self.__summaries.items():\n",
    "            res[className] = 1\n",
    "            for i in range(len(classValues)):\n",
    "                mean, stdev = classValues[i]\n",
    "                x = input_data[i]\n",
    "                res[className] *= self.__calc_single_probability(x, mean, stdev)\n",
    "        return res\n",
    "\n",
    "\n",
    "    def __calc_single_probability(self, x, mean, stdev):\n",
    "        \"\"\"\n",
    "        Апостериорная вероятность принадлежности объекта к определенному классу (с предрасчитанными средний и отклонением).\n",
    "        Магия по формуле.\n",
    "        :param x:\n",
    "        :param mean:\n",
    "        :param stdev:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        exponent = math.exp(-(math.pow(x-mean, 2)/(2*math.pow(stdev, 2))))\n",
    "        return (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\n",
    "\n",
    "    def score(self, inputs, outputs):\n",
    "        \"\"\"\n",
    "        Классифицирует входные данные, сравнивает с выходными и возвращает точность классификации.\n",
    "        :param inputs:\n",
    "        :param outputs:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        predicted = self.predict(inputs)\n",
    "        correct = 0\n",
    "        for i in range(len(inputs)):\n",
    "            if outputs[i] == predicted[i]:\n",
    "                correct += 1\n",
    "        return correct / float(len(inputs))\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'MyGaussianNaiveBayes'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Сравнение алгоритмов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сравнения различных алгоритмов напишем функцию, которая будет загружать выборку и разбивать её на обучающую и тестовую. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def load_dataset(split_ratio=None, normalize=True):\n",
    "    dataset_full = np.loadtxt(open(\"../pima-indians-diabetes.data.csv\", \"r\"), delimiter=\",\", skiprows=0, dtype=np.float64)\n",
    "    inputs = dataset_full[:, :-1]\n",
    "    outputs = dataset_full[:, -1]\n",
    "    outputs = outputs.astype(np.int64, copy=False)\n",
    "    if split_ratio is None:\n",
    "        return inputs, outputs, None, None\n",
    "    inputs_train, inputs_test, outputs_train, outputs_test \\\n",
    "        = train_test_split(inputs, outputs, test_size=split_ratio, random_state=random.randint(0, 1000))\n",
    "    if normalize:\n",
    "        std_scale = preprocessing.StandardScaler().fit(inputs_train)\n",
    "        inputs_train = std_scale.transform(inputs_train)\n",
    "        inputs_test = std_scale.transform(inputs_test)\n",
    "    return inputs_train, outputs_train, inputs_test, outputs_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для сравнения алгоритмов выгрузим датасет и подсунем его библиотечным (sci-kit learn) и самописным KNN и NaiveBayes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyGaussianNaiveBayes \n",
      "Accuracy:  0.7435064935064936 \n",
      "--------------\n",
      "GaussianNB(priors=None) \n",
      "Accuracy:  0.714285714286 \n",
      "--------------\n",
      "MyKNN with N_neighbors=75 \n",
      "Accuracy:  0.7045454545454546 \n",
      "--------------\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=75, p=2,\n",
      "           weights='uniform') \n",
      "Accuracy:  0.704545454545 \n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "def load_dataset(split_ratio=None, normalize=True):\n",
    "    dataset_full = np.loadtxt(open(\"../pima-indians-diabetes.data.csv\", \"r\"), delimiter=\",\", skiprows=0, dtype=np.float64)\n",
    "    inputs = dataset_full[:, :-1]\n",
    "    outputs = dataset_full[:, -1]\n",
    "    outputs = outputs.astype(np.int64, copy=False)\n",
    "    if split_ratio is None:\n",
    "        return inputs, outputs, None, None\n",
    "    inputs_train, inputs_test, outputs_train, outputs_test \\\n",
    "        = train_test_split(inputs, outputs, test_size=split_ratio, random_state=random.randint(0, 1000))\n",
    "    if normalize:\n",
    "        std_scale = preprocessing.StandardScaler().fit(inputs_train)\n",
    "        inputs_train = std_scale.transform(inputs_train)\n",
    "        inputs_test = std_scale.transform(inputs_test)\n",
    "    return inputs_train, outputs_train, inputs_test, outputs_test\n",
    "\n",
    "def main():\n",
    "    # готовим датасет\n",
    "    inputs_train, outputs_train, inputs_test, outputs_test = load_dataset(split_ratio=.4, normalize=True)\n",
    "    # готовим классификаторы\n",
    "    classificators = [\n",
    "        MyGaussianNaiveBayes(),\n",
    "        GaussianNB(),\n",
    "        MyKNN(n_neighbors=75),\n",
    "        KNeighborsClassifier(n_neighbors=75)\n",
    "    ]\n",
    "    # оцениваем работу каждого классификатора\n",
    "    for clf in classificators:\n",
    "        clf.fit(inputs_train, outputs_train)\n",
    "        print(clf, '\\nAccuracy: ', clf.score(inputs_test, outputs_test), '\\n--------------')\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе лабораторной работы были реализованы алгоритмы: наивный байесовский и метод K ближайших соседей."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Наивный байесовский алгоритм работает лучше на выбранном датасете.\n",
    "- Реализованный и библиотечный методы К ближайших соседей имеют одинаковую точность, что говорит о том, что алгоритм работает в точности как библиотечный. По крайней мере на представленной выборке.\n",
    "- Точность реализованного наивного Байеса отличается от библиотечного (~1-4%). Чаще всего в худшую сторону, но бывает, что в лучшую.   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3.0
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}