{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №5. Метрики качества классификации"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выполнили: Рутин Василий, Гордеев Станислав"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все лабораторные работы доступны по адресу: https://github.com/Omenstudio/ML_IFMO_LABS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Постановка задачи"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Прочитать теоретическую часть\n",
    "2. Для двух любых методов классификации из предыдущих работ и своего набора данных посчитать следующие метрики качества:<br>\n",
    "    a. Точность классификации (Classification Accuracy)<br>\n",
    "    b. Логарифм функции правдоподобия (Logarithmic Loss)<br>\n",
    "    c. Область под кривой ошибок (Area Under ROC Curve)<br>\n",
    "    d. Матрица неточностей (Confusion Matrix)<br>\n",
    "    e. Отчет классификации (Classification Report)<br>\n",
    "3. Для более точных результатов использовать кросс-валидацию\n",
    "4. Сравнить применимость используемых классификаторов, основываясь на полученных метриках"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Исходные данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задача классификации: определение наличия заболевания (диабет) у женщин.<br>\n",
    "Датасет доступен по адресу: https://archive.ics.uci.edu/ml/datasets/Pima+Indians+Diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Количество записей: 768<br>\n",
    "Количество атрибутов: 8 плюс класс.<br>\n",
    "Все атрибуты представлены числовыми значениями:\n",
    "1. Количество беременностей (шт.)\n",
    "2. Концентрация плазмы глюкозы (ммоль/л)\n",
    "3. Диастолическое давление (мм. рт. столба)\n",
    "4. Толщина кожной складки (мм.)\n",
    "5. Содержание инсулина (мкЕд/мл)\n",
    "6. Индекс массы тела (кг/м2)\n",
    "7. Предрасположенность по родословной линии (Diabetes pedigree function)\n",
    "8. Возраст (лет)\n",
    "9. Класс: наличие диабета (0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ход работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функцию, считывающую датасет, возьмем из предыдущих лабораторных работ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "def load_dataset(split_ratio=None, normalize=True):\n",
    "    dataset_full = np.loadtxt(open(\"../pima-indians-diabetes.data.csv\", \"r\"), delimiter=\",\", skiprows=0, dtype=np.float64)\n",
    "    inputs = dataset_full[:, :-1]\n",
    "    outputs = dataset_full[:, -1]\n",
    "    outputs = outputs.astype(np.int64, copy=False)\n",
    "    if split_ratio is None:\n",
    "        return inputs, outputs, None, None\n",
    "    inputs_train, inputs_test, outputs_train, outputs_test \\\n",
    "        = train_test_split(inputs, outputs, test_size=split_ratio, random_state=random.randint(0, 1000))\n",
    "    if normalize:\n",
    "        std_scale = preprocessing.StandardScaler().fit(inputs_train)\n",
    "        inputs_train = std_scale.transform(inputs_train)\n",
    "        inputs_test = std_scale.transform(inputs_test)\n",
    "    return inputs_train, outputs_train, inputs_test, outputs_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Далее напишем метод, который будет принимать на вход модель, входные и выходные данные, и выводить в консоль все метрики качества. Для повышения точности будем использовать кросс-валидацию."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "def print_score(model, inputs, outputs):\n",
    "    print('Model: {}'.format(model))\n",
    "    print('CrossValidation results:')\n",
    "    #\n",
    "    scorings = ['accuracy', 'neg_log_loss', 'roc_auc']\n",
    "    for scoring in scorings:\n",
    "        # кросс-валидация здесь!\n",
    "        results = cross_val_score(model, inputs, outputs, cv=KFold(n_splits=10), scoring=scoring)\n",
    "        print('{}: {:.3f} ({:.3f})'.format(scoring, results.mean(), results.std()))\n",
    "    #\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(inputs, outputs, test_size=0.4)\n",
    "    model.fit(X_train, Y_train)\n",
    "    predicted = model.predict(X_test)\n",
    "    #\n",
    "    print('ConfusionMatrix:\\n', confusion_matrix(Y_test, predicted))\n",
    "    print('ClassificationReport:\\n', classification_report(Y_test, predicted))\n",
    "    #\n",
    "    print('--------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тестируем Наивный Байесовский алгоритм и метод К ближайших соседей."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: GaussianNB(priors=None)\n",
      "CrossValidation results:\n",
      "accuracy: 0.755 (0.043)\n",
      "neg_log_loss: -0.619 (0.171)\n",
      "roc_auc: 0.818 (0.045)\n",
      "ConfusionMatrix:\n",
      " [[161  51]\n",
      " [ 31  65]]\n",
      "ClassificationReport:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.76      0.80       212\n",
      "          1       0.56      0.68      0.61        96\n",
      "\n",
      "avg / total       0.75      0.73      0.74       308\n",
      "\n",
      "--------------\n",
      "Model: KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=75, p=2,\n",
      "           weights='uniform')\n",
      "CrossValidation results:\n",
      "accuracy: 0.746 (0.051)\n",
      "neg_log_loss: -0.531 (0.058)\n",
      "roc_auc: 0.786 (0.068)\n",
      "ConfusionMatrix:\n",
      " [[190  19]\n",
      " [ 76  23]]\n",
      "ClassificationReport:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.91      0.80       209\n",
      "          1       0.55      0.23      0.33        99\n",
      "\n",
      "avg / total       0.66      0.69      0.65       308\n",
      "\n",
      "--------------\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    inputs, outputs, _, _ = load_dataset()\n",
    "    print_score(GaussianNB(), inputs, outputs)\n",
    "    print_score(KNeighborsClassifier(n_neighbors=75), inputs, outputs)\n",
    "\n",
    "\n",
    "main()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ходе лабораторной работы посчитаны основные метрики качества для Наивного Байесовского алгоритма и метода К средних. Сделаны следующие выводы:<br>\n",
    "1. Точность GaussianNB(0.755) выше, чем KNN(0.746). Правда, всего на 0.9%. Следуеть посмотреть на другие метрики, возможно, они помогут выбрать лучший алгоритм. \n",
    "2. Результаты log_loss и roc_auc говорят в пользу KNN.\n",
    "3. Анализ матрицы неточностей показывает, что неверных срабатываний в обоих алгоритмах примерно поровну, а вот положительно угаданных больше в KNN. \n",
    "4. Метрика точности (precision) говорит, что \"доверять\" лучше GaussianNB.\n",
    "5. Метрика полноты (recall) говорит, что KNN хорошо \"угадывает\" отсутствие диабета и очень плохо его наличие."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
